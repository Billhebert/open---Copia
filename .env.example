# =============================================================================
# Multi-Tenant AI Chat Platform - Environment Variables
# =============================================================================

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
PORT=3000
NODE_ENV=development

# -----------------------------------------------------------------------------
# Database (PostgreSQL)
# -----------------------------------------------------------------------------
DATABASE_URL="postgresql://user:password@localhost:5432/chat_platform?schema=public"

# -----------------------------------------------------------------------------
# Authentication & Security
# -----------------------------------------------------------------------------
# IMPORTANT: Change these secrets in production! Minimum 32 characters.
JWT_ACCESS_SECRET=change-me-access-secret-min-32-chars-please
JWT_REFRESH_SECRET=change-me-refresh-secret-min-32-chars-please

# -----------------------------------------------------------------------------
# Vector Database (Qdrant)
# -----------------------------------------------------------------------------
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

# -----------------------------------------------------------------------------
# Embeddings Configuration
# -----------------------------------------------------------------------------
# Provider: 'ollama' (local) or 'minimax' (cloud)
EMBEDDING_PROVIDER=ollama

# Ollama (local embeddings and text generation)
OLLAMA_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
OLLAMA_MODEL=llama3.2

# MiniMax (cloud embeddings - https://api.minimax.chat)
MINIMAX_API_KEY=
MINIMAX_GROUP_ID=
# MiniMax default model: embo-01 (1024 dimensions)

# RAG Performance Tuning
# Number of chunks processed per batch (default: 15, higher = faster but more memory)
RAG_BATCH_SIZE=15
# Number of batches processed in parallel (default: 3, higher = faster but more CPU/GPU)
RAG_PARALLEL_BATCHES=3
# Examples:
#   Conservative (slow machines): RAG_BATCH_SIZE=5, RAG_PARALLEL_BATCHES=1
#   Balanced (default): RAG_BATCH_SIZE=15, RAG_PARALLEL_BATCHES=3
#   Aggressive (powerful machines): RAG_BATCH_SIZE=20, RAG_PARALLEL_BATCHES=5

# -----------------------------------------------------------------------------
# File Storage
# -----------------------------------------------------------------------------
FILE_STORE_PATH=./storage
FILE_STORE_TYPE=local

# For S3 (future migration):
# FILE_STORE_TYPE=s3
# AWS_ACCESS_KEY_ID=
# AWS_SECRET_ACCESS_KEY=
# AWS_S3_BUCKET=
# AWS_REGION=us-east-1

# -----------------------------------------------------------------------------
# Legacy OpenCode AI SDK Integration
# -----------------------------------------------------------------------------
SDK_PORT=7501

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------
MODELS_FILE=./models.json

# -----------------------------------------------------------------------------
# Vault (for BYO Keys - future)
# -----------------------------------------------------------------------------
# VAULT_URL=http://localhost:8200
# VAULT_TOKEN=

# -----------------------------------------------------------------------------
# Rate Limiting
# -----------------------------------------------------------------------------
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
LOG_LEVEL=info

# =============================================================================
# AI Model Provider API Keys (Optional - depends on models.json)
# =============================================================================

# OpenAI
OPENAI_API_KEY=

# Anthropic
ANTHROPIC_API_KEY=

# Google
GOOGLE_GENERATIVE_AI_API_KEY=
GEMINI_API_KEY=

# GitHub Copilot
GITHUB_TOKEN=

# Groq
GROQ_API_KEY=

# DeepSeek
DEEPSEEK_API_KEY=

# Mistral
MISTRAL_API_KEY=

# Together AI
TOGETHER_API_KEY=

# OpenRouter
OPENROUTER_API_KEY=

# Other providers (add as needed)
# See models.json for the complete list of supported providers
